# ğŸ§  Sign Language Interpreter ğŸ¤Ÿ | Real-Time Gesture & action to Text & Action Conversion

> Built with by Meghana Kommana  
> Empowering communication through AI + Computer Vision.

---

## ğŸš€ Project Overview

This Sign Language Interpreter is a **real-time gesture recognition system** that detects hand gestures using a webcam and interprets them into:
- ğŸ”¤ **Alphabets (Aâ€“K)** â€“ trained using hand landmarks
- ğŸ’¬ **Custom actions** â€“ like â€œI love youâ€ or â€œWhatâ€™s up?â€ using full-hand gestures

This project solves the communication gap between hearing and speech-impaired individuals and others by **translating hand signs into letters or meaningful sentences** using machine learning and computer vision.

---

## ğŸ¯ Key Features

- âœ… Real-time hand detection with **MediaPipe**
- ğŸ¥ Webcam-based input
- ğŸ§  Machine learning model using **scikit-learn (MLPClassifier)**
- ğŸª„ Predicts both **letter signs** and **custom action gestures**
- ğŸ” Switch modes (letter â†” action) by pressing `M`
- ğŸ“¸ Custom gesture data collection using your webcam
- ğŸ—£ï¸ (Optional) Speak predictions out loud with `os.system("say")`
- ğŸ“‚ Neatly organized training, prediction, and data collection files

---

## ğŸ› ï¸ Tech Stack

| Layer            | Tech Used                          |
|------------------|------------------------------------|
| âœ‹ Hand Detection | `MediaPipe`, `OpenCV`              |
| ğŸ§  ML Model       | `scikit-learn`, `joblib`, `numpy`  |
| ğŸ“ Data Handling  | `pandas`, `CSV`, `LabelEncoder`    |
| ğŸ¤ Speech (opt.)  | macOS `say` command                |
| ğŸ“¦ Packaging      | Python 3.9+, Virtualenv            |

---

